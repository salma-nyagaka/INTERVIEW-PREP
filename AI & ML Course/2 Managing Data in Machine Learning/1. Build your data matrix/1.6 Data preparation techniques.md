# Data Understanding

## Define the Problem

This is step zero of any machine learning project. Before we even perform any action, we need to first answer **who** and **what** we are modeling. This can be answered by defining the problem statement and breaking it down into units of analysis.  

## Exploratory Data Analysis

Exploratory Data Analysis (EDA) is the act of “poking around” the data for any obvious insights. This entails bringing in the data (or a subset thereof) into our coding environment, performing a descriptive summary using common statistical libraries, and making plots such as scatter plots and histograms for any obvious insights.

## Visualization

There is a wealth of visualization techniques that are designed to help us understand our data better. These techniques help us determine the skew of data, the shape of its distribution, and if any outlier is present. Incorporating visualization in our data preparation workflow is essential so that we can have better types of cleanup and feature engineering that are needed prior to training the model.

# Data Preparation

## Sampling

Once we have a concrete idea of the problem we are trying to solve, we need to ensure our data is meaningful in the context of the problem. This can be thought of as having the data drawn from the same environment as production.

For example, if we are trying to train a self-driving car, the images we train should be from actual roads and from the same types of hardware as the ones used in production. We wouldn’t use images from video games even though they may be more easily obtained.

In addition, we want to ensure our data points are independently and identically distributed (I.I.D), meaning that they should be drawn from the same distribution and be independent of each other.

## Specifying Label

The training dataset for supervised learning must have some “ground truth” (label) associated with each data point. The label is what we are trying to predict, and this is the goal of our machine learning model.

Depending on the use case, we may cast labels from one data type to another. For example, turning a customer review from the range of 1.0 to 5.0 stars into binary values of **GOOD** or **BAD**. This is also where we make the determination of whether the model should be a classification model or a regression model.

## The Data Matrix

The underlying code for most machine learning models is optimized to process data in an N-dimensional table — we call this format the **data matrix**, whereby:

- Each row represents an example or data point
- The last column represents the label
- Each of the remaining columns represents a feature

A typical task for a machine learning engineer is to arrange data into this format prior to feeding it into a machine learning model.

## Data Cleaning

Most data is inherently “dirty.” This can be caused by problems such as system error, data corruption, and poor quality control. In data cleaning, we ensure our data does not contain missing values or any unwanted outliers.

When these conditions are encountered, we perform actions such as dropping the row or applying **winsorization** in order to ensure our data matrix is clean and free of data that are non-representative of the problem we are trying to solve.

# Modeling

## Feature Engineering

The data available to us may not always be readily suitable for training a machine learning model. Sometimes this is due to formatting incompatibility, other times the models themselves are optimized for certain types of input.

**Feature engineering** concerns bringing data into the right format and representations required by the intended machine learning model.
