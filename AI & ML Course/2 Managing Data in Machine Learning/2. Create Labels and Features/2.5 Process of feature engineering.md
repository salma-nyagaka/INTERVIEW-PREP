### Feature Transformation in Machine Learning

Features sometimes need to be transformed in order to be understood by their intended machine learning models.

Some feature transformation techniques are optional but ideal, as they lead to better results in model performance.

**One-hot encoding** is the most important feature transformation technique that turns categorical values into binary vectors.


### Expected Input and Output Data Format for Various Feature Transformation Techniques

| Technique               | Input                   | Output        |
|-------------------------|--------------------------|----------------|
| Binary indicator        | Categorical or numeric   | Binary (0/1)   |
| One-hot encoding        | Categorical              | Binary (0/1)   |
| Functional transformation | Numeric               | Numeric        |
| Interaction terms       | Numeric                  | Numeric        |
| Binning                 | Numeric                  | Categorical    |
| Scaling                 | Numeric                  | Numeric        |




After defining the modeling population and label, the next step is **feature engineering**, which involves two main strategies:

1. **Mapping predictive or causal concepts to data representations** – this is the first and most impactful strategy, often guided by intuition and a conceptual model of the problem. It involves aggregating and converting raw data into meaningful features.
2. **Manipulating data for machine learning APIs** – the second strategy focuses on preparing these features in ways models can use (e.g., normalization, encoding). Of these transformations, **one-hot encoding** is essential for categorical data and cannot be skipped.

While both strategies are important, most of the model's performance depends on the first strategy—correctly capturing meaningful concepts in the data.
