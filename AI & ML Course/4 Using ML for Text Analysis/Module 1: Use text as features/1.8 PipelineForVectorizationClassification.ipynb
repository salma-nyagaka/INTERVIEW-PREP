{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a Pipeline for Text Vectorization and Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo, you will see how to use scikit-learn pipelines to chain together the TF-IDF vectorization and classification processes that you used in the previous demo. Using a pipeline, you will use text vectorization to transform book review text into numerical feature vectors and use these features to train a classifier, all in one step. You will then add a grid search to the pipeline to find the optimal hyperparameter configuration and you will evaluate the performance of this optimal configuration using ROC-AUC.\n",
    "\n",
    "**<font color='red'>Note: some of the code cells in this notebook may take a while to run</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n",
    "\n",
    "Before you get started, import a few packages. Run the code cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import matplotlib as plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also import the scikit-learn `TfidfVectorizer` class to implement a TF-IDF vectorizer, the scikit-learn `LogisticRegression` class, the `train_test_split()` function for splitting the data into training and test sets,`GridSearchCV` to perform model selection to find the model with the best cross-validation score, and the functions `roc_auc_score` and `plot_roc_curve` to evaluate the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load a 'ready-to-fit' Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with the book review dataset taken from Amazon.com reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(os.getcwd(), \"data\", \"bookReviews.csv\")\n",
    "df = pd.read_csv(filename, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Positive Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This was perhaps the best of Johannes Steinhof...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This very fascinating book is a story written ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The four tales in this collection are beautifu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The book contained more profanity than I expec...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We have now entered a second time of deep conc...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Positive Review\n",
       "0  This was perhaps the best of Johannes Steinhof...             True\n",
       "1  This very fascinating book is a story written ...             True\n",
       "2  The four tales in this collection are beautifu...             True\n",
       "3  The book contained more profanity than I expec...            False\n",
       "4  We have now entered a second time of deep conc...             True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Training and Test Data Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Labeled Examples \n",
    "\n",
    "\n",
    "Let's create labeled examples from our dataset. We will have one text feature and one label. \n",
    "The code cell below carries out the following steps:\n",
    "\n",
    "* Gets the `Positive_Review` column from DataFrame `df` and assign it to the variable `y`. This will be our label. \n",
    "* Gets the column `Review` from DataFrame `df` and assigns it to the variable `X`. This will be our feature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1973,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Positive Review'] \n",
    "X = df['Review']\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of 0       This was perhaps the best of Johannes Steinhof...\n",
       "1       This very fascinating book is a story written ...\n",
       "2       The four tales in this collection are beautifu...\n",
       "3       The book contained more profanity than I expec...\n",
       "4       We have now entered a second time of deep conc...\n",
       "                              ...                        \n",
       "1968    I purchased the book with the intention of tea...\n",
       "1969    There are so many design books, but the Graphi...\n",
       "1970    I am thilled to see this book being available ...\n",
       "1971    As many have stated before me the book starts ...\n",
       "1972    I love this book! It is a terrific blend of ha...\n",
       "Name: Review, Length: 1973, dtype: object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1973,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Labeled Examples into Training and Test Sets\n",
    "\n",
    "Let's split our data into training and test sets with 75% of the data being the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500     There is a reason this book has sold over 180,...\n",
       "1047    There is one thing that every cookbook author ...\n",
       "1667    Being an engineer in the aerospace industry I ...\n",
       "1646    I have no idea how this book has received the ...\n",
       "284     It is almost like dream comes true when I saw ...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.75, random_state=1234)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Set up a TF-IDF + Logistic Regression Pipeline\n",
    "\n",
    "We will look at a new way to chain together various methods to automate the machine learning workflow. We will use  the scikit-learn `Pipeline` utility. For more information, consult the online [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html). First, let's import `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below uses a scikit-learn pipeline to perform TF-IDF vectorization and the fitting of a logistic regression model to the transformed data.\n",
    "\n",
    "This is implemented in the following steps:\n",
    "\n",
    "1. First we create a list containing the steps to perform in the pipeline. Items in the list will be executed in the order in which they appear.\n",
    "\n",
    "    Each item in the list is a tuple consisting of two items: \n",
    "    1. A descriptive name of what is being performed. You can create any name you'd like.\n",
    "    2. The code to run.\n",
    "    \n",
    "    \n",
    "2. Next we create a Pipeline object and supply it the list of steps using the `step` parameter.\n",
    "\n",
    "\n",
    "3. We use this pipeline as we would any model object and fit this pipeline to the original training data. Note that when calling the `fit()` method on the pipeline object, all of the steps in the pipeline are performed on the data.\n",
    "\n",
    "\n",
    "4. Finally, we use the pipeline object to make predictions on the original test data. When calling the `predict_proba()` method on the pipeline object, all of the steps in the pipeline are performed on the data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin ML pipeline...\n",
      "End pipeline\n"
     ]
    }
   ],
   "source": [
    "print('Begin ML pipeline...')\n",
    "\n",
    "# 1. Define the list of steps:\n",
    "s = [\n",
    "        (\"vectorizer\", TfidfVectorizer(ngram_range=(1,2), min_df=10)),\n",
    "        (\"model\", LogisticRegression(max_iter=200))\n",
    "    ]\n",
    "\n",
    "# 2. Define the pipeline:\n",
    "model_pipeline = Pipeline(steps=s)\n",
    "\n",
    "# We can use the pipeline the way would would use a model object \n",
    "# when fitting the model on the training data testing on the test data:\n",
    "\n",
    "# 3. Fit the pipeline to the training data\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 4. Make predictions on the test data. \n",
    "# Save the second column to the variable 'probability_predictions'\n",
    "probability_predictions = model_pipeline.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('End pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance\n",
    "\n",
    "Let's see the performance of our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on the test data: 0.9195\n"
     ]
    }
   ],
   "source": [
    "auc_score = roc_auc_score(y_test, probability_predictions)\n",
    "\n",
    "print('AUC on the test data: {:.4f}'.format(auc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some case, scikit-learn gives you the ability to provide a pipeline object as an argument to a function. One such function is `plot_roc_curve()`. You'll see in the online [documentation](https://scikit-learn.org/0.23/modules/generated/sklearn.metrics.plot_roc_curve.html) that this function can take a pipeline (estimator) as an argument.\n",
    "\n",
    "Let's import the function and try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x785a3dc83048>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import plot_roc_curve\n",
    "\n",
    "plot_roc_curve(model_pipeline, X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in newer versions of scikit-learn, this function has been replaced by [RocCurveDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.RocCurveDisplay.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Perform a GridSearchCV on the Pipeline to Find the Best Hyperparameters \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform a grid search on the pipeline object `model_pipeline` to find the hyperparameter configuration for hyperparameter $C$ (for the logistic regression) and for the $ngram\\_range$ (for the TF-IDF vectorizer) that results in the best cross-validation score.\n",
    "\n",
    "<i>Note the following</i>:\n",
    "\n",
    "When running a grid search on a pipeline, the hyperparameter names you specify in the parameter grid are the names of the pipeline items (the descriptive names that you provided to the items in the pipeline) followed by two underscores, followed by the actual hyperparameter names. \n",
    "\n",
    "For example, note what we named the pipeline items above:\n",
    "\n",
    "```s = [\n",
    "        (\"vectorizer\", TfidfVectorizer(ngram_range=(1,2), min_df=10)),\n",
    "        (\"model\", LogisticRegression(max_iter=200))\n",
    "    ]\n",
    "```\n",
    "\n",
    "We named the the classifier `model` and the vectorizer `vectorizer`. \n",
    "\n",
    "Since we named our classifier `model`, the hyperparameter name for $C$ that we would use as the key in `param_grid` is `model__C`. \n",
    "\n",
    "Since we named our vectorizer `vectorizer`, the hyperparameter name for $ngram\\_range$ that we would use as the key in `param_grid` is `vectorizer__ngram_range`. \n",
    "\n",
    "You can find a list containing possible pipeline hyperparameter keys that you can use by running the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['memory', 'steps', 'verbose', 'vectorizer', 'model', 'vectorizer__analyzer', 'vectorizer__binary', 'vectorizer__decode_error', 'vectorizer__dtype', 'vectorizer__encoding', 'vectorizer__input', 'vectorizer__lowercase', 'vectorizer__max_df', 'vectorizer__max_features', 'vectorizer__min_df', 'vectorizer__ngram_range', 'vectorizer__norm', 'vectorizer__preprocessor', 'vectorizer__smooth_idf', 'vectorizer__stop_words', 'vectorizer__strip_accents', 'vectorizer__sublinear_tf', 'vectorizer__token_pattern', 'vectorizer__tokenizer', 'vectorizer__use_idf', 'vectorizer__vocabulary', 'model__C', 'model__class_weight', 'model__dual', 'model__fit_intercept', 'model__intercept_scaling', 'model__l1_ratio', 'model__max_iter', 'model__multi_class', 'model__n_jobs', 'model__penalty', 'model__random_state', 'model__solver', 'model__tol', 'model__verbose', 'model__warm_start'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the Parameter Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__C': [0.1, 1, 10], 'vectorizer__ngram_range': [(1, 1), (1, 2)]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'vectorizer__ngram_range':[(1,1), (1,2)],\n",
    "               'model__C':[0.1, 1, 10]\n",
    "              }\n",
    "\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Grid Search Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Grid Search...\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "[CV] model__C=0.1, vectorizer__ngram_range=(1, 1) ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... model__C=0.1, vectorizer__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] model__C=0.1, vectorizer__ngram_range=(1, 1) ....................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..... model__C=0.1, vectorizer__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] model__C=0.1, vectorizer__ngram_range=(1, 1) ....................\n",
      "[CV] ..... model__C=0.1, vectorizer__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] model__C=0.1, vectorizer__ngram_range=(1, 2) ....................\n",
      "[CV] ..... model__C=0.1, vectorizer__ngram_range=(1, 2), total=   0.8s\n",
      "[CV] model__C=0.1, vectorizer__ngram_range=(1, 2) ....................\n",
      "[CV] ..... model__C=0.1, vectorizer__ngram_range=(1, 2), total=   0.8s\n",
      "[CV] model__C=0.1, vectorizer__ngram_range=(1, 2) ....................\n",
      "[CV] ..... model__C=0.1, vectorizer__ngram_range=(1, 2), total=   0.8s\n",
      "[CV] model__C=1, vectorizer__ngram_range=(1, 1) ......................\n",
      "[CV] ....... model__C=1, vectorizer__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] model__C=1, vectorizer__ngram_range=(1, 1) ......................\n",
      "[CV] ....... model__C=1, vectorizer__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] model__C=1, vectorizer__ngram_range=(1, 1) ......................\n",
      "[CV] ....... model__C=1, vectorizer__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] model__C=1, vectorizer__ngram_range=(1, 2) ......................\n",
      "[CV] ....... model__C=1, vectorizer__ngram_range=(1, 2), total=   0.8s\n",
      "[CV] model__C=1, vectorizer__ngram_range=(1, 2) ......................\n",
      "[CV] ....... model__C=1, vectorizer__ngram_range=(1, 2), total=   0.8s\n",
      "[CV] model__C=1, vectorizer__ngram_range=(1, 2) ......................\n",
      "[CV] ....... model__C=1, vectorizer__ngram_range=(1, 2), total=   0.8s\n",
      "[CV] model__C=10, vectorizer__ngram_range=(1, 1) .....................\n",
      "[CV] ...... model__C=10, vectorizer__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] model__C=10, vectorizer__ngram_range=(1, 1) .....................\n",
      "[CV] ...... model__C=10, vectorizer__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] model__C=10, vectorizer__ngram_range=(1, 1) .....................\n",
      "[CV] ...... model__C=10, vectorizer__ngram_range=(1, 1), total=   0.3s\n",
      "[CV] model__C=10, vectorizer__ngram_range=(1, 2) .....................\n",
      "[CV] ...... model__C=10, vectorizer__ngram_range=(1, 2), total=   0.8s\n",
      "[CV] model__C=10, vectorizer__ngram_range=(1, 2) .....................\n",
      "[CV] ...... model__C=10, vectorizer__ngram_range=(1, 2), total=   0.9s\n",
      "[CV] model__C=10, vectorizer__ngram_range=(1, 2) .....................\n",
      "[CV] ...... model__C=10, vectorizer__ngram_range=(1, 2), total=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed:   10.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Running Grid Search...')\n",
    "\n",
    "# 1. Run a Grid Search with 3-fold cross-validation\n",
    "grid = GridSearchCV(model_pipeline, param_grid=param_grid, cv=3, verbose=2, scoring = 'roc_auc')\n",
    "\n",
    "# 2. Fit the model (grid) on the training data \n",
    "grid_search = grid.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify the Best Hyperparameter Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to see the best pipeline configuration that was determined by the grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=10, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('model',\n",
       "                 LogisticRegression(C=10, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=200,\n",
       "                                    multi_class='auto', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below prints the best hyperparameters. It accesses them using the `best_params_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__C': 10, 'vectorizer__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that in the past, after we obtained the best hyperparameter values from a grid search, we re-trained a model with these values in order to evaluate the performance. This time we will do something different. Just as we can pass a `Pipeline` object directly to `plot_roc_curve()` to evaluate the model, we can pass `grid_search.best_estimator_` to the function `plot_roc_curve()` to evaluate the model. We also pass in the test data (`X_test` and `y_test`). This allows the test data to be passed through the entire pipeline, using the best hyperparameter values.\n",
    "\n",
    "Note that you can simply just pass `grid_search` to the function as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x785a92a577b8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc_curve(grid_search.best_estimator_, X_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
