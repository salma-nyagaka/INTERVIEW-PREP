**Summary:**

Before building a machine learning model, there are three foundational questions to address:

1. **Where do I find my data?**
2. **Where do I build the model?**
3. **How do I access these systems?**

### **1. Data Access in Practice:**

* **On the job**, data often lives in a **data lake**, populated by logs or SQL-based updates from the application layer.
* Data can be:

  * **Structured** (e.g., database tables with consistent schema)
  * **Unstructured** (e.g., raw log files on Linux servers)
* In real-world roles, you'll need to:

  * Know **SQL** for structured databases.
  * Learn to **process and convert unstructured data** into structured formats, since ML models require consistent input schemas.

### **2. Model Development Environment:**

* Most work is done in an **IDE (Integrated Development Environment)**.
* **Jupyter Notebooks** are the most popular tool for ML model development:

  * Allow code execution, data exploration, and visualizations.
  * Support markdown for inline documentation.
  * Are widely used in both education and industry for sharing and presenting work.

### **3. Accessing Systems:**

* Data usually resides on **remote Linux servers** (not your local laptop).
* You'll commonly use the **Linux command line interface (CLI)** to:

  * Navigate the server
  * Manage files and folders
  * Launch Jupyter notebooks
* Even on your local machine, learning the command line (e.g., via **iTerm on Mac**) is beneficial for a smoother ML workflow.

### **Key Takeaway:**

Understanding how to **locate, access, and prepare data**, along with the right tools (like Jupyter and CLI), is essential for effective machine learning workâ€”especially in industry settings.
